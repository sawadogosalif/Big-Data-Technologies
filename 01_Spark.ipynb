{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un DataFrame PySpark  équivaut à une table relationnelle dans Spark SQL et peut être créé à l'aide de diverses fonctions dans SparkSession :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why PySpark Dataframe\n",
    "\n",
    "**RDD**-   Lorsque vous souhaitez une transformation et des actions de bas niveau, nous utilisons des RDD. De plus, lorsque nous avons besoin d'abstractions de haut niveau, nous utilisons des RDD.\n",
    "Lors de l'exécution d'opérations simples de regroupement et d'agrégation, l'API RDD est plus lente. \n",
    "Depuis les API RDD, un utilisateur doit définir le schéma manuellement.\n",
    "\n",
    "**DataFrame** -   Lorsque nous avons besoin d'un haut niveau d'abstraction et pour les données non structurées, telles que les flux multimédias ou les flux de texte.En effectuant une analyse exploratoire, en créant des statistiques agrégées sur les données, les dataframes sont plus rapides.Dans dataframe, il n'est pas nécessaire de spécifier un schéma. Généralement, il découvre le schéma automatiquement.\n",
    "\n",
    "En réalité, grossièrement les RDD sont devenus obsolètes. Et la raison derrière cela est qu'au fur et à mesure que Spark est devenu mature, il a commencé à ajouter des fonctionnalités pour le  data warehousing, le big data analytics, et la data science.\n",
    "\n",
    "Pour ce faire, il a introduit les DataFrames PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, HiveContext, SparkConf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setMaster('local[*]')                # setMaster('yarn-client')\n",
    "conf = conf.setAppName('my_second_app')\n",
    "conf =  conf.set('spark.ui.port', '5050')               # definition du uri spark\n",
    "conf= conf.set('spark.sql.shuffle.partitions','4')\n",
    "sc = SparkContext(conf=conf)                            # Instanciation du context spark\n",
    "hctx = HiveContext(sc)                                  # Instanciation du context hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = hctx.sql(\"USE Upec_2022\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recuperation de données\n",
    "query = \"SELECT * FROM iad_stb_model\"\n",
    "\n",
    "#Execution de la requête\n",
    "dtf = hctx.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dat_phto: string (nullable = true)\n",
      " |-- idnt_comp_serv: long (nullable = true)\n",
      " |-- rdn_samp: integer (nullable = true)\n",
      " |-- anc_actv: integer (nullable = true)\n",
      " |-- ref_date: string (nullable = true)\n",
      " |-- dat_rsil_cds: string (nullable = true)\n",
      " |-- flg_rsil: integer (nullable = true)\n",
      " |-- val_debit_down: float (nullable = true)\n",
      " |-- libl_res: string (nullable = true)\n",
      " |-- libl_tech: string (nullable = true)\n",
      " |-- nb_iad: integer (nullable = true)\n",
      " |-- iad_anc_info: integer (nullable = true)\n",
      " |-- iad_userkey2: string (nullable = true)\n",
      " |-- fdate_iad_anc: integer (nullable = true)\n",
      " |-- iad_model: string (nullable = true)\n",
      " |-- iad_vendor: string (nullable = true)\n",
      " |-- iad_softwarever: string (nullable = true)\n",
      " |-- rk_asc_iad_conf: integer (nullable = true)\n",
      " |-- nb_stv: integer (nullable = true)\n",
      " |-- stb_anc_info: integer (nullable = true)\n",
      " |-- fdate_stb_anc: integer (nullable = true)\n",
      " |-- stb_model: string (nullable = true)\n",
      " |-- stb_vendor: string (nullable = true)\n",
      " |-- stb_softwarever: string (nullable = true)\n",
      " |-- rk_asc_stb_conf: integer (nullable = true)\n",
      " |-- noinadinfo: integer (nullable = true)\n",
      " |-- nostbinfo: integer (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# dtf est un dataframe\n",
    "print(dtf.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+--------+------------+--------+--------------+--------+---------+------+------------+------------+-------------+---------+----------+--------------------+---------------+------+------------+-------------+--------------+----------+---------------+---------------+----------+---------+\n",
      "|idnt_comp_serv|rdn_samp|anc_actv|dat_rsil_cds|flg_rsil|val_debit_down|libl_res|libl_tech|nb_iad|iad_anc_info|iad_userkey2|fdate_iad_anc|iad_model|iad_vendor|     iad_softwarever|rk_asc_iad_conf|nb_stv|stb_anc_info|fdate_stb_anc|     stb_model|stb_vendor|stb_softwarever|rk_asc_stb_conf|noinadinfo|nostbinfo|\n",
      "+--------------+--------+--------+------------+--------+--------------+--------+---------+------+------------+------------+-------------+---------+----------+--------------------+---------------+------+------------+-------------+--------------+----------+---------------+---------------+----------+---------+\n",
      "|  610002561962|       0|      26|           ?|       0|       20000.0|      NC|     xDSL|     1|           4|          3P|            8|    3965b|     Sagem|B400FC_RECO_7.6.2...|              4|     1|          17|           17|RTI422-320_BYT|     Sagem|      G07.25.66|              1|         0|        0|\n",
      "|  610000395217|       0|      61|           ?|       0|       20000.0|      BT|     xDSL|     1|           1|          2P|            1|     3504|     Sagem|       5B10I4-5B00IU|              2|  null|        null|         null|             ?|         ?|              ?|           null|         0|        0|\n",
      "|  610001993598|       0|      33|           ?|       0|        8000.0|      FT|     xDSL|     1|           5|          2P|            5|    TG787|   Thomson|  B11001_MAIN_8.6.62|              5|  null|        null|         null|             ?|         ?|              ?|           null|         0|        0|\n",
      "|  610000673832|       0|      55|           ?|       0|       20000.0|      BT|     xDSL|     1|           0|          3P|            0|    TG787|   Thomson|  B11001_MAIN_8.6.64|              5|     1|           4|           11|   DBI8500-BYT|   Thomson|       02.08.41|              2|         0|        0|\n",
      "|  610003687556|       0|      11|           ?|       0|       20000.0|      BT|     xDSL|     1|           7|          3P|            7|    3965b|     Sagem|B400FC_RECO_7.6.2...|              1|     1|           1|            5| RTI90-160_BYT|     Sagem|         6.7.92|              1|         0|        0|\n",
      "+--------------+--------+--------+------------+--------+--------------+--------+---------+------+------------+------------+-------------+---------+----------+--------------------+---------------+------+------------+-------------+--------------+----------+---------------+---------------+----------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtf.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traitement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes **pyspark.sql.function**  permettent de faire des réquètes Spark SQL et DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supprimer des colonnes : **drop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf = dtf.drop(dtf.dat_phto)\n",
    "dtf = dtf.drop(dtf.ref_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifier des colonnes  : **withColumn** , **when**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf = dtf.withColumn(\"flg_rsil\", F.when(dtf.dat_rsil_cds=='?',0).otherwise(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtrer des colonnes / Sélectionner des colonnes : **select**, **SelectExpr**, **where**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+--------+\n",
      "|idnt_comp_serv|flg_rsil|rdn_samp|\n",
      "+--------------+--------+--------+\n",
      "|  610004644264|       0|       1|\n",
      "|  610001492507|       0|       1|\n",
      "|  610004556803|       0|       1|\n",
      "|  610002465916|       0|       1|\n",
      "|  610001621486|       0|       1|\n",
      "+--------------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#dtf2 = dtf.select(dtf.idnt_comp_serv, dtf.flg_rsil, dtf.rdn_samp).where(\"rdn_samp=1\")\n",
    "dtf2 = dtf.select('idnt_comp_serv', 'flg_rsil', 'rdn_samp').where(\"rdn_samp=1\")\n",
    "dtf2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+\n",
      "|        chpA|flg_rsil|\n",
      "+------------+--------+\n",
      "|610004644264|       0|\n",
      "|610001492507|       0|\n",
      "|610004556803|       0|\n",
      "|610002465916|       0|\n",
      "|610001621486|       0|\n",
      "+------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ajouter un label au nom de la colonne et l'afficher\n",
    "dtf.selectExpr('idnt_comp_serv AS chpA', 'flg_rsil').where(\"rdn_samp=1 AND flg_rsil=0\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf2.registerTempTable('tmp_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+\n",
      "|    tableName|isTemporary|\n",
      "+-------------+-----------+\n",
      "|iad_stb_model|      false|\n",
      "|     svi_data|      false|\n",
      "| svi_data_orc|      false|\n",
      "| svi_data_pqt|      false|\n",
      "|    tmp_table|       true|\n",
      "+-------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hctx.sql(\"SHOW tables\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faire des jointures **JOIN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+--------+------------+--------+--------------+--------+---------+------+------------+------------+-------------+---------+----------+--------------------+---------------+------+------------+-------------+--------------+----------+---------------+---------------+----------+---------+--------------+--------+--------+\n",
      "|idnt_comp_serv|rdn_samp|anc_actv|dat_rsil_cds|flg_rsil|val_debit_down|libl_res|libl_tech|nb_iad|iad_anc_info|iad_userkey2|fdate_iad_anc|iad_model|iad_vendor|     iad_softwarever|rk_asc_iad_conf|nb_stv|stb_anc_info|fdate_stb_anc|     stb_model|stb_vendor|stb_softwarever|rk_asc_stb_conf|noinadinfo|nostbinfo|idnt_comp_serv|flg_rsil|rdn_samp|\n",
      "+--------------+--------+--------+------------+--------+--------------+--------+---------+------+------------+------------+-------------+---------+----------+--------------------+---------------+------+------------+-------------+--------------+----------+---------------+---------------+----------+---------+--------------+--------+--------+\n",
      "|  610004644264|       1|       1|           ?|       0|       20000.0|      BT|     xDSL|     1|           0|          3P|            0| TVW620.I|      UBEE|B400FB_RECO_9.1.9...|              2|     1|           1|            1|RTI422-320_BYT|     Sagem|      G07.67.06|              2|         0|        0|  610004644264|       0|       1|\n",
      "|  610001492507|       1|      40|           ?|       0|        2432.0|      FT|     xDSL|     1|           3|          2P|            6|    TG787|   Thomson|  B11001_MAIN_8.6.62|              5|  null|        null|         null|             ?|         ?|              ?|           null|         0|        0|  610001492507|       0|       1|\n",
      "|  610004556803|       1|       2|           ?|       0|       20000.0|      BT|     xDSL|     1|           1|          3P|            1|    5330b|     Sagem|B120FF_RECO_9.1.9...|              2|     1|           2|            2|RTI422-320_BYT|     Sagem|      G07.67.00|              1|         0|        0|  610004556803|       0|       1|\n",
      "+--------------+--------+--------+------------+--------+--------------+--------+---------+------+------------+------------+-------------+---------+----------+--------------------+---------------+------+------------+-------------+--------------+----------+---------------+---------------+----------+---------+--------------+--------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtf.join(dtf2, ((dtf.idnt_comp_serv == dtf2.idnt_comp_serv) & (dtf.rdn_samp == dtf2.rdn_samp)), \"inner\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculer des aggrégats : **Groupby**, **count**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|flg_rsil| count|\n",
      "+--------+------+\n",
      "|       0|601449|\n",
      "|       1|  8495|\n",
      "+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculer des aggrégats\n",
    "dtf.groupBy('flg_rsil').count().show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+------+\n",
      "|flg_rsil|libl_tech| count|\n",
      "+--------+---------+------+\n",
      "|       0|        ?|  4698|\n",
      "|       0|     FTTH|  3375|\n",
      "|       1|        ?|   373|\n",
      "|       0|     xDSL|509593|\n",
      "|       0|      THD| 83783|\n",
      "|       1|      THD|  1170|\n",
      "|       1|     xDSL|  6910|\n",
      "|       1|     FTTH|    42|\n",
      "+--------+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtf.groupBy('flg_rsil','libl_tech').count().show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+------+\n",
      "|flg_rsil|libl_tech| count|\n",
      "+--------+---------+------+\n",
      "|       0|        ?|  4698|\n",
      "|       0|     FTTH|  3375|\n",
      "|       1|        ?|   373|\n",
      "|       0|     xDSL|509593|\n",
      "|       0|      THD| 83783|\n",
      "|       1|      THD|  1170|\n",
      "|       1|     xDSL|  6910|\n",
      "|       1|     FTTH|    42|\n",
      "+--------+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtf.groupBy(dtf.flg_rsil, dtf.libl_tech).count().show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcule de covariance, corrélation entre 2 colonnes **cov, corr**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-279.37907793573163"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Le format de val_debit_down n'est pas entier\n",
    "dtf.selectExpr('flg_rsil', 'CAST(val_debit_down AS INT) as val_debit_down').\\\n",
    "where(dtf.rdn_samp == 1).cov(\"flg_rsil\", \"val_debit_down\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.014757322753845652"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtf.selectExpr('flg_rsil', 'CAST(val_debit_down AS INT) as val_debit_down').\\\n",
    "where(dtf.rdn_samp == 1).corr(\"flg_rsil\", \"val_debit_down\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **FreqItem** : éléments qui apparaissent plus de X % de la colonne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+----------------------+\n",
      "|rdn_samp_freqItems|anc_actv_freqItems|dat_rsil_cds_freqItems|\n",
      "+------------------+------------------+----------------------+\n",
      "|[1, 0]            |[4, 39]           |[26/02/2015, ?]       |\n",
      "+------------------+------------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# selection des modalités ayant plus de 50%\n",
    "dtf.stat.freqItems([\"rdn_samp\", \"anc_actv\", \"dat_rsil_cds\"], 0.50).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tableau croisé à deux entrée **crosstab**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----+------+------+-----+-----+------+-----+\n",
      "|flg_rsil_libl_res|   ?|Axione|    BT|BT_HZ|   FT|    NC|  NCC|\n",
      "+-----------------+----+------+------+-----+-----+------+-----+\n",
      "|                1| 373|   219|  4025|   42|  690|  1976| 1170|\n",
      "|                0|4698| 16527|310830| 3375|38488|143748|83783|\n",
      "+-----------------+----+------+------+-----+-----+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtf.crosstab(\"flg_rsil\", \"libl_res\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminations des doublons  avec **dropDuplicates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "609935"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# doublons parfaits\n",
    "dtf.dropDuplicates().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[idnt_comp_serv: bigint, rdn_samp: int, anc_actv: int, dat_rsil_cds: string, flg_rsil: int, val_debit_down: float, libl_res: string, libl_tech: string, nb_iad: int, iad_anc_info: int, iad_userkey2: string, fdate_iad_anc: int, iad_model: string, iad_vendor: string, iad_softwarever: string, rk_asc_iad_conf: int, nb_stv: int, stb_anc_info: int, fdate_stb_anc: int, stb_model: string, stb_vendor: string, stb_softwarever: string, rk_asc_stb_conf: int, noinadinfo: int, nostbinfo: int]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# doublons sur des colonnes définies\n",
    "dtf.dropDuplicates(['flg_rsil', 'rdn_samp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valeurs manquantes : **na**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "381590"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtf.dropna().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python UDF avec Pyspark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDF, veut dire Fonctions définies par l’utilisateur. \n",
    "L’UDF nous permettra d’appliquer les fonctions directement dans les dataframes et les bases de données SQL en python. \n",
    "Autrement une fonction python n'est pas directement utilisable sur PySpark avec un simple Apply. \n",
    "En pyspark , UDF est la solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def removeCar(str):\n",
    "    return re.sub(\"[a-zA-Z]\", \"\", str, 0)\n",
    "\n",
    "def removeDig(str):\n",
    "    return re.sub(\"\\d\", \"\", str, 0)\n",
    "\n",
    "def removeSpe(str):\n",
    "    return re.sub(\"\\W\", \"\", str, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition de  UDF comme data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "schema = StringType()\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "UDFremoveDig = udf(removeDig, schema)\n",
    "UDFremoveCar = udf(removeCar, schema)\n",
    "UDFremoveSpe = udf(removeSpe, schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisation de L'UDF avec withColumn (PySpark DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------+---------------------+-------------------------+--------------------------------+\n",
      "|iad_softwarever                      |noDigit              |noCar                    |noSpe                           |\n",
      "+-------------------------------------+---------------------+-------------------------+--------------------------------+\n",
      "|B400FC_RECO_7.6.22-B40004_MAIN_9.1.50|BFC_RECO_..-B_MAIN_..|400__7.6.22-40004__9.1.50|B400FC_RECO_7622B40004_MAIN_9150|\n",
      "|5B10I4-5B00IU                        |BI-BIU               |5104-500                 |5B10I45B00IU                    |\n",
      "|B11001_MAIN_8.6.62                   |B_MAIN_..            |11001__8.6.62            |B11001_MAIN_8662                |\n",
      "|B11001_MAIN_8.6.64                   |B_MAIN_..            |11001__8.6.64            |B11001_MAIN_8664                |\n",
      "|B400FC_RECO_7.6.22-B40004_MAIN_9.1.50|BFC_RECO_..-B_MAIN_..|400__7.6.22-40004__9.1.50|B400FC_RECO_7622B40004_MAIN_9150|\n",
      "|B400FC_RECO_7.6.22-B40004_MAIN_9.1.50|BFC_RECO_..-B_MAIN_..|400__7.6.22-40004__9.1.50|B400FC_RECO_7622B40004_MAIN_9150|\n",
      "|7B104A-7B004G-CM_5.5.1mp3_110721     |BA-BG-CM_..mp_       |7104-7004-_5.5.13_110721 |7B104A7B004GCM_551mp3_110721    |\n",
      "|B400FB_RECO_9.1.96-B40005_MAIN_9.2.36|BFB_RECO_..-B_MAIN_..|400__9.1.96-40005__9.2.36|B400FB_RECO_9196B40005_MAIN_9236|\n",
      "|B11001_MAIN_8.6.62                   |B_MAIN_..            |11001__8.6.62            |B11001_MAIN_8662                |\n",
      "|B11001_MAIN_8.6.64                   |B_MAIN_..            |11001__8.6.64            |B11001_MAIN_8664                |\n",
      "|B400FC_RECO_7.6.22-B40004_MAIN_9.1.38|BFC_RECO_..-B_MAIN_..|400__7.6.22-40004__9.1.38|B400FC_RECO_7622B40004_MAIN_9138|\n",
      "|B400FB_RECO_9.1.96-B40005_MAIN_9.2.36|BFB_RECO_..-B_MAIN_..|400__9.1.96-40005__9.2.36|B400FB_RECO_9196B40005_MAIN_9236|\n",
      "|B400FB_RECO_9.1.96-B40005_MAIN_9.2.36|BFB_RECO_..-B_MAIN_..|400__9.1.96-40005__9.2.36|B400FB_RECO_9196B40005_MAIN_9236|\n",
      "|B11001_MAIN_8.6.62                   |B_MAIN_..            |11001__8.6.62            |B11001_MAIN_8662                |\n",
      "|B11001_MAIN_8.6.62                   |B_MAIN_..            |11001__8.6.62            |B11001_MAIN_8662                |\n",
      "|5B10I4-5B00IM                        |BI-BIM               |5104-500                 |5B10I45B00IM                    |\n",
      "|B11001_MAIN_8.6.62                   |B_MAIN_..            |11001__8.6.62            |B11001_MAIN_8662                |\n",
      "|B400FC_RECO_7.6.22-B40004_MAIN_9.1.50|BFC_RECO_..-B_MAIN_..|400__7.6.22-40004__9.1.50|B400FC_RECO_7622B40004_MAIN_9150|\n",
      "|B120FF_RECO_9.1.92-B12001_MAIN_9.2.32|BFF_RECO_..-B_MAIN_..|120__9.1.92-12001__9.2.32|B120FF_RECO_9192B12001_MAIN_9232|\n",
      "|B510FF_RECO_8.7.10-B51001_MAIN_8.7.34|BFF_RECO_..-B_MAIN_..|510__8.7.10-51001__8.7.34|B510FF_RECO_8710B51001_MAIN_8734|\n",
      "+-------------------------------------+---------------------+-------------------------+--------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtf.withColumn(\"noDigit\", UDFremoveDig(\"iad_softwarever\"))\\\n",
    "    .withColumn(\"noCar\", UDFremoveCar(\"iad_softwarever\"))\\\n",
    "    .withColumn(\"noSpe\", UDFremoveSpe(\"iad_softwarever\"))\\\n",
    "    .select(\"iad_softwarever\", \"noDigit\", \"noCar\", \"noSpe\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customization de functions python avec SPARK SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "hctx.registerFunction(\"UDFremoveCar\",lambda x : removeCar(x), StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|     iad_softwarever|               noCar|\n",
      "+--------------------+--------------------+\n",
      "|B400FC_RECO_7.6.2...|400__7.6.22-40004...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = hctx.sql(\"SELECT iad_softwarever, UDFremoveCar(iad_softwarever) as noCar FROM iad_stb_model LIMIT 100\").show(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
